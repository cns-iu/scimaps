---
id: 106
name: submissions_14
subpage: other
title: 14th Iteration Submissions
description: null
last_updated: '2018-02-01'
---
.submission-box{ height: 420px !important; } $(document).ready(function() { $('.parent-container').magnificPopup({ delegate: 'a', // child items selector, by clicking on it popup will open type: 'inline' // other options }); });

Submissions for the 14th Iteration of the _Places & Spaces: Mapping Science_ Exhibit (2018)
===========================================================================================

  

[

![](images/submissions/14/patent-citation-spectroscopy.jpg)

1\. Patent Citation Spectroscopy (PCS): Online retrieval of landmark patents based on an algorithmic approach
-------------------------------------------------------------------------------------------------------------

#### Jordan Comins, Stephanie A. Carmack and Loet Leydesdorff



](#1)[

![](images/submissions/14/cr-explorer.jpg)

2\. Reference Publication Year Spectroscopy (RPYS) using CRExplorer
-------------------------------------------------------------------

#### Andreas Thor, Lutz Bornmann and Werner Marx



](#2)[

![](images/submissions/14/gravity-apple-tree.jpg)

3\. The Gravity Apple Tree
--------------------------

#### Mariana Espinosa



](#3)[

![](images/submissions/14/conceptual-networks-gravitation.jpg)

4\. Conceptual networks for gravitation and other space-time theories
---------------------------------------------------------------------

#### Mariana Espinosa



](#4)[

![](images/submissions/14/politoscope.jpg)

5\. Politoscope - the life of political communities through the lens of social media
------------------------------------------------------------------------------------

#### David Chavalarias, Noé Gaumont and Maziyar Panahi



](#5)[

![](images/submissions/14/climate-tweetoscope.jpg)

6\. Climate Tweetoscope - It's time to dive into Climate Change!
----------------------------------------------------------------

#### David Chavalarias, Maziyar Panahi and Samuel Castillo



](#6)[

![](images/submissions/14/violence-info.jpg)

7\. Violence Info
-----------------

#### Christian Siegrist, Peter Gassner, Gerhard Bliedung, Tomas Carnecky, Luc Guillemot, Ece Kavlak and Benjamin Wiederkehr



](#7)[

![](images/submissions/14/megatrend-impact-analyzer.jpg)

8\. Megatrend and Intervention Impact Analyzer for Jobs
-------------------------------------------------------

#### Rain Öpik, Innar Liiv and Toomas Kirt



](#8)[

![](images/submissions/14/biomarker.jpg)

9\. Accumulating Evidence and Research Organization (AERO) Mapping
------------------------------------------------------------------

#### Spencer Hey



](#9)[

![](images/submissions/14/unfolding-library.jpg)

10\. The Unfolding Library
--------------------------

#### Benjamin Schmidt



](#10)[

![](images/submissions/14/datausa.jpg)

11\. DATAUSA
------------

#### Datawheel & Deloitte



](#11)[](#12)

[

![](images/submissions/14/cluster-mapping.jpg)

12\. Cluster Mapping
--------------------

](#12)

#### [](#12)[Various Authors](http://clustermapping.us/content/project-leadership-team)

[

![](images/submissions/14/istanbul-urban-database.jpg)

13\. Istanbul Urban Database
----------------------------

#### Nil Tuzcu



](#13)[

![](images/submissions/14/rhythm-of-food.jpg)

14\. The Rhythm of Food
-----------------------

#### Google News Lab and Truth & Beauty



](#14)

1\. Patent Citation Spectroscopy (PCS): Online retrieval of landmark patents based on an algorithmic approach
=============================================================================================================

![](images/submissions/14/patent-citation-spectroscopy.jpg)

### Website(s):

[www.leydesdorff.net/comins/pcs/](www.leydesdorff.net/comins/pcs/)  

### Author(s):

Jordan Comins, Stephanie A. Carmack and [Loet Leydesdorff](https://www.leydesdorff.net/)

### Abstract:

One essential component in the construction of patent landscapes in biomedical research and development (R&D) is identifying the most seminal patents. Hitherto, the identification of seminal patents required subject matter experts within biomedical areas. In this brief communication, we report an analytical method and tool, Patent Citation Spectroscopy (PCS), for the online identification of landmark patents in user-specified areas of biomedical innovation. Using USPTO data, PCS mines the cited references within large sets of patents and provides an estimate of the most historically impactful prior work. We show the efficacy of PCS in two case studies of biomedical innovation with clinical relevance: (1) RNA interference and (2) cholesterol. PCS mined and analyzed 4,065 cited references related to patents on RNA interference and correctly identified the foundational patent of this technology, as independently reported by subject matter experts on RNAi intellectual property. Secondly, we apply PCS to a broad set of patents dealing with cholesterol – a case study chosen to reflect a more general, as opposed to expert, patent search query. PCS mined through 11,326 cited references and identified the seminal patent as that for Lipitor, the groundbreaking medication for treating high cholesterol as well as the pair of patents underlying Repatha. These cases suggest that PCS provides a useful method for identifying seminal patents in areas of biomedical innovation and therapeutics.

### Submission PDF:

[Paper](docs/submissions/14/patient-citation-spectroscopy.pdf)

2\. Reference Publication Year Spectroscopy (RPYS) using CRExplorer
===================================================================

![](images/submissions/14/cr-explorer.jpg)

### Website(s):

[www.crexplorer.net](www.crexplorer.net)

### Author(s):

Andreas Thor, Lutz Bornmann and Werner Marx

### Abstract:

The program CitedReferencesExplorer (CRExplorer) can be used to analyse the cited references (CRs) data in a publication set retrieved from Web of Science (WoS, Clarivate Analytics) or Scopus (Elsevier). CRExplorer produces the results of the analyses in a graphical or table format for inclusion in a paper or presentation. The program can be retrieved from www.crexplorer.net. It is written in the Java programming language and, thus, runs on most hardware and operating system platforms. The program can be used free of charge. (1) It can be launched directly from www.crexplorer.net using Java Web Start Launcher. (2) An executable JAR file can be downloaded from [www.crexplorer.net](www.crexplorer.net).

The program was primarily developed to identify those publications in fields, of topics, or by researchers which have been most frequently referenced. It is especially suitable to study the historical roots of fields, topics, or researchers by Reference Publication Year Spectroscopy (RPYS). RPYS is based on the analysis of the frequency with which references are cited in the publications of a specific research field in terms of the publication years of these CRs. The origins show up in the form of more or less pronounced peaks mostly caused by individual publications that are cited particularly frequently. CRExplorer can also be used to identify landmark publications of citation classics in fields, of topics, or by researchers CRExplorer reads, analyses, and edits the cited references of publications which are previously retrieved from WoS or Scopus. In order to analyse the cited references, the user can consult (1) a graph for identifying most frequently cited reference publication years (RPYs) and (2) a table of cited references which account for specific reference publication years. Field-normalization in impact measurement is ensured by the first step of the analysis of cited references: the selection of the publication set on which citation impact is measured.

### Submission PDF:

[Paper](docs/submission/14/cr-explorer.pdf)

3\. The Gravity Apple Tree
==========================

![](images/submissions/14/gravity-apple-tree.jpg)

### Website(s):

[https://prezi.com/rdkivznlhgga/the-gravity-apple-tree/](https://prezi.com/rdkivznlhgga/the-gravity-apple-tree/)

### Author(s):

[Maria Espinosa](http://representacionymodelizacion.org/integrantes/mariana-espinosa-aldama/)

### Abstract:

The Gravity Apple Tree is a tree like network that portraits the development of alternative theories of gravitation during the 20th century. It relates authors and theoretical concepts, anchored through publication dates of seminal articles. It has a time line, where crucial experiments on gravitation are indicated, contrasting with the theoretical realm. Visualization was made with Adobe Illustrator, it's presented in a PREZI format and includes links to doi addresses of seminal articles and portraits of authors. Data was obtained from recognized theoretical classifications from Clifford Will, Friedrich Hehl, Stacy Mc Gaugh and Phillip Mannheim among others. This improved version includes important contributions to the branch for General Relativity (GR), as well as some important recent contributions such as Ligo's experiment (2016). The tree gives us insight of a plurality of theories and the roads that have been explored. It helps on showing periods of great production, periods of growth of branches and decrease of contributions as in the war periods or when unviability is shown (as in the case of theories with prior geometry). It's inclusive, as mote than 150 authors are mentioned, although it still does not include all the alternative theories that can be found in literature. This visualization may be helpful for science teachers and students.

Related article: [http://iopscience.iop.org/article/10.1088/1742-6596/600/1/012050/meta](http://iopscience.iop.org/article/10.1088/1742-6596/600/1/012050/meta) Related work in progress: Visualizations of conceptual networks for gravitation and other space-time theories at [http:/132.247.183.198/](http:/132.247.183.198/)

4\. Conceptual networks for gravitation and other space-time theories
=====================================================================

![](images/submissions/14/conceptual-networks-gravitation.jpg)

### Website(s):

[http:/132.247.183.198/](http:/132.247.183.198/)

### Author(s):

[Maria Espinosa](http://representacionymodelizacion.org/integrantes/mariana-espinosa-aldama/)

### Abstract:

On the attempt to show the complex conceptual networks among theories of gravitation I have set up databases or contexts based on renowned theoretical reconstructions and analyzed their formal concepts (FCA)through the software conexp1-3 and Wolfram Mathematica. Interactive visualizations are done in D3 and presented in a web page.

Resulting networks allow clicking on nodes to move them. Double clicking on nodes highlights parents and children, showing, for example, which theories follow geodesics, which ones live in a Lorentzian space-time, which ones share Einstein's equations, etc. Classes of attributes are color coded, easily showing the hierarchical reconstruction of theories, where topological and geometrical aspects are set on top levels, while physical considerations are in lower levels. Classes of theories, theories and models can be easily identified. Extra information on terms is displayed on the side as the cursor passes through tags (Choosing the ideal info is work in progress, but the set up is working alright). Mathematical symbols are displayed via MathJax library. Networks displayed: Space-time theories, Classical theories, Metric theories, f(R) theories. Other networks are work in progress.

5\. Politoscope - the life of political communities through the lens of social media
====================================================================================

![](images/submissions/14/politoscope.jpg)

### Website(s):

[https://presidentielle2017.politoscope.org/dashboard/](ttps://presidentielle2017.politoscope.org/dashboard)

### Author(s):

[David Chavalarias](https://iscpif.fr/chavalarias/), Noé Gaumont, and [Maziyar Panahi](hhttps://iscpif.fr/maziyar/)

### Abstract:

As well as political parties, which use big data coming from social networks to analyze the opinions of their fellow citizens, the Politoscope puts research tools at the disposal of citizens to analyze the speeches and opinions of political figures and their communities. This political macroscope was designed for the 2017 French presidential election. Available online as well as on display at the 9 months TERRA DATA exhibition at the Cité des Sciences et de l’Industrie, it gaves in real-time, during the last month of the presidential campaign, the pulse of the online political communities of the main candidates running for the election, as well as the reconstruction, over several months, of their positions on major political issues.

Through the analysis of dozens of millions of political and media tweets, the Politoscope makes it possible to visualize the socio-semantic trends of a multi-polar political environment and dive into the debates of the political communities as well as the main verbatims of their leaders. It relies on a new methodology described in Noe Gaumont, Maziyar Panahi, David Chavalarias (forthcoming 2017) Reconstruction of the socio-semantic dynamics of political activist Twitter networks – Method and application to the 2017 French Presidential election The Politoscope was probably one of the first initiative to offer citizens of an entire country the opportunity to follow in real time the tribulations of political parties and their militant base from massive Twitter data (see https://presidentielle2017.politoscope.org/dashboard). After the intensive use of this type of data by political parties to screen the views of their citizens, we are convinced that these researches and associated projects will be part of the future rebalancing of information between political elites and citizens in social contexts as sensitive to our democracies as elections.

We are convinced that this kind of macroscope are necessary to raise awarness of the raising entanglement between social networks and electoral processes worldwide.

Online ressources: \* Politoscope dashboard : [https://presidentielle2017.politoscope.org/dashboard](https://presidentielle2017.politoscope.org/dashboard) \* Online website with analyses from the Politoscope : [http://politoscope.org](http://politoscope.org)

NB : the interface is currently in French but could be easily translated for a Place ans Space exhibition with a standalone version working on any modern web browser.

### Submission PDF:

[Paper](docs/submissions/14/politoscope.pdf)

6\. Climate Tweetoscope - It's time to dive into Climate Change!
================================================================

![](images/submissions/14/climate-tweetoscope.jpg)

### Website(s):

[http://tweetoscope.iscpif.fr/COP21/desktop.html?lang=EN](http://tweetoscope.iscpif.fr/COP21/desktop.html?lang=EN)

### Author(s):

[David Chavalarias](https://iscpif.fr/chavalarias/), [Maziyar Panahi](hhttps://iscpif.fr/maziyar/), and Samuel Castillo.

### Abstract:

When the media or us talk about climate change, we mean temperatures, storms, droughts, cyclones, polar bears ; while the researchers talk about observations, circulation models, temperature anomalies...But do the concerns of scientists sometime converge with those of the general public and media? This is what you can see thanks to climate Tweetoscope which offers interactive exploration of topics related to climate change and its consequences. Analyzing news in the web since May 2015 with Twitter as a proxy, the Tweetoscope aims to provide an evolving collective representation of questions and debates on this major societal issue.

### Submission PDF:

[Paper](docs/submissions/14/climate-tweetoscope.pdf)

7\. Violence Info
=================

![](images/submissions/14/violence-info.jpg)

### Website(s):

[http://apps.who.int/violence-info/](http://apps.who.int/violence-info/)

### Author(s):

Christian Siegrist, Peter Gassner, Gerhard Bliedung, Tomas Carnecky, Luc Guillemot, Ece Kavlak and Benjamin Wiederkehr

### Abstract:

High-quality data on interpersonal violence are scattered across myriad specialist websites, statistical databases, technical reports, and exclusive academic journals. Together with the World Health Organization we built a platform which brings together the existing scientific information including studies on the prevalence of interpersonal violence, its consequences, risk factors, prevention and response strategies. The data for each category of violence is analyzable through various visualizations to present a more accurate picture of the magnitude, severity, and consequences for individuals and society.

The platform is divided into three main parts: For each of the violence types, we created a dedicated page with a summary of the most important facts and figures to communicate the statistically very complex data to a broad audience in an accessible way. The second part covers country-specific information on their action plans, laws and programs created to prevent violence. For scientists and journalists, we further provide a tool which allows them to explore the over 3,000 studies within the Violence Info platform. The full set can be filtered by author, sex, age or income group and other parameters.

8\. Megatrend and Intervention Impact Analyzer for Jobs
=======================================================

![](images/submissions/14/megatrend-impact-analyzer.jpg)

### Website(s):

[https://rainopik.github.io/eubdhack-megatrend/](https://rainopik.github.io/eubdhack-megatrend/)

### Author(s):

Rain Öpik, Innar Liiv and Toomas Kirt

### Abstract:

We present a visual method for representing the complex labour market internal structure from the perspective of similar occupations based on shared skills; and a prototype tool for interacting with the visualization, together with an extended description of graph construction and the necessary data processing for linking multiple heterogeneous data sources. Since the labour market is not an isolated phenomenon and is constantly impacted by external trends and interventions, the presented method is designed to enable adding extra layers of external information. For instance, what is the impact of a megatrend or an intervention on the labour market? Which parts of the labour market are the most vulnerable to an approaching megatrend or planned intervention? A case study of analysing the labour market together with the megatrend of automation and computerization of jobs is presented.

The following heterogeneous data sources were combined for the visualization method:

*   EURES CV and job vacancy data set (European Commission 2017)
*   ESCO classifier in RDF format (European Commission 2013)
*   List of jobs susceptible to automation/computerisation (Frey and Osborne 2016)
*   Occupation classifications mapping table from Occupation classifications crosswalks – from O\*NET-SOC to ISCO (Hardy et al. 2016)

The basis of the visualization is the occupation graph, which was built from the ESCO classifier. A graph node denotes an occupation and a link is defined when two occupations are similar in terms of shared essential skills. Each node has metadata attached – statistics from EURES (e.g. number of vacancies, number of job seekers) and other external datasets (e.g. probability of automation of the job). Nodes in the graph are colour-coded by values from connected external data.

### Submission PDF:

[Paper](docs/submissions/14/megatrend-intervention.pdf)

9\. Accumulating Evidence and Research Organization (AERO) Mapping
==================================================================

![](images/submissions/14/biomarker.jpg)

### Website(s):

### Author(s):

Spencer Hey

### Abstract:

One major challenge for clinical research is that no single stakeholder is responsible for coordinating the entire research program. This can lead to duplicative studies that are addressing the same question or low-value studies that continue to test a hypothesis that has already been confirmed or refuted. Since every investigation involving human subjects is ethically required to redeem its costs and burdens by making a significant contribution to scientific knowledge, it is important to minimize these research inefficiencies.

The Accumulating Evidence and Research Organization (AERO) graph is a visual tool that can elucidate, and ultimately reduce, duplicative or low-value studies. The basic idea behind the approach is to systematically represent research activities in a comprehensive and comprehensible way—and thereby facilitate better communication, coordination, and decision-making among various research stakeholders.

A prototype AERO graph is now available at https://www.portalresearch.org/aero-graph.html. This example depicts the research program of cholesteryl ester transfer protein inhibitors (CETPi) as treatments for cardiovascular disease. This class of drugs was tested in 100 trials, involving nearly 100,000 human subjects in total. The AERO graph of this research program immediately conveys this immense investment, while also allowing the user to further explore the details about each individual trial. In so doing, it can help to sharpen ethical deliberation. For example, informed consent requires that a patient has knowledge of the prior research surrounding and leading up to a study, as well as knowledge of any alternative studies that might be more suitable for them. This interactive representation allows patients to do just that.

This AERO graph is based on data extracted from public trial registries and the published scientific literature. It employs a script written in Python and the Bokeh visualization library to create an interactive scatter plot.

### Submission PDF:

[Paper](docs/submissions/14/biomarker.pdf)

10\. The Unfolding Library
==========================

![](images/submissions/14/unfolding-library.jpg)

### Website(s):

[http://benschmidt.org/hathi\_scatter](http://benschmidt.org/hathi_scatter)

### Author(s):

[Benjamin Schmidt](http://benschmidt.org/)

### Abstract:

This is a visualization of 14 million books contained in the Hathi Trust Digital Library, representing most of the digital texts available to researchers today. They are clustered in a two-dimensional, zoomable visualization that reveals progressively greater detail on user zoom events and which can display different sorts of library metadata as colors or labels.

The primary goal is to make the immense number of books scanned by Google and others in recent years discoverable. Books in the public domain can be read directly in the visualization. At high levels of resolution, it reveals serendipitous relations of individual texts it unveils; at medium scales, by showing the overlap between disciplines and languages, it invites users to consider the interconnection of different fields of knowledge; and at the largest it helps users to understand the immensity of the digital library of books.

Underlying data comes from the Hathi Trust Research Center's Extracted Features Dataset; in order to visualize in two dimensions, each book was reduced to 1280 dimensions using random projection on the term-document matrix (a paper describing the precise method is currently under review). This was then reduced down to 100 dimensions using PCA, and then to two dimensions using the LargeVis algorithm.

The D3-based visualization renders points to an in-browser canvas element, allowing full interaction while displaying as many as 100,000 points at a time. Data is stored in hierarchically-structured flat files that are loaded as needed. This is a novel approach to massive scatterplots that can be easily served from most hardware. It includes a "scrollytelling" narration to provide a point of entry into the visualization.

### Citations:

*   Schmidt, "Stable Random Projection," paper under review at Cultural Analytics
*   Boris Capitanu, Ted Underwood, Peter Organisciak, Timothy Cole, Maria Janina Sarol, J. Stephen Downie (2016). The HathiTrust Research Center Extracted Feature Dataset (1.0) \[Dataset\]. HathiTrust Research Center, [http://dx.doi.org/10.13012/J8X63JT3](http://dx.doi.org/10.13012/J8X63JT3).
*   "Visualizing Large-scale and High-dimensional Data" Jian Tang, Jingzhou Liu, Ming Zhang, Qiaozhu Mei. [https://arxiv.org/abs/1602.00370](https://arxiv.org/abs/1602.00370). [http://dx.doi.org/10.1145/2872427.2883041](http://dx.doi.org/10.1145/2872427.2883041)

11\. DATAUSA
============

![](images/submissions/14/datausa.jpg)

### Website(s):

[https://datausa.io/](https://datausa.io/)

### Author(s):

[Datawheel & Deloitte](https://datausa.io/about/team/)

### Abstract:

In 2014, Deloitte, Datawheel, and Cesar Hidalgo, Professor at the MIT Media Lab and Director of MacroConnections, came together to embark on an ambitious journey -- to understand and visualize the critical issues facing the United States in areas like jobs, skills and education across industry and geography. And, to use this knowledge to inform decision making among executives, policymakers and citizens.

Our team, comprised of economists, data scientists, designers, researchers and business executives, worked for over a year with input from policymakers, government officials and everyday citizens to develop Data USA, the most comprehensive website and visualization engine of public US Government data. Data USA tells millions of stories about America. Through advanced data analytics and visualization, it tells stories about: places in America—towns, cities and states; occupations, from teachers to welders to web developers; industries--where they are thriving, where they are declining and their interconnectedness to each other; and education and skills, from where is the best place to live if you’re a computer science major to the key skills needed to be an accountant.

Data USA puts public US Government data in your hands. Instead of searching through multiple data sources that are often incomplete and difficult to access, you can simply point to Data USA to answer your questions. Data USA provides an open, easy-to-use platform that turns data into knowledge. It allows millions of people to conduct their own analyses and create their own stories about America – its people, places, industries, skill sets and educational institutions. Ultimately, accelerating society’s ability to learn and better understand itself.

How can Data USA be useful? If you are an executive, it can help you better understand your customers and talent pool. It can inform decisions on where to open or relocate your business or plant. You may also want to build on the Data USA platform using the API and integrate additional data. If you are a recent college graduate, Data USA can help you find locations with the greatest opportunities for the job you want and the major you have. If you are a policymaker, Data USA can be a powerful input to economic and workforce development programs. Or, you may be a public health professional and want to dive into behavioral disease patterns across the country. These are just a few examples of how an open data platform like Data USA can benefit everyday citizens, business and government.

12\. Cluster Mapping
====================

![](images/submissions/14/cluster-mapping.jpg)

### Website(s):

[http://clustermapping.us/](http://clustermapping.us/)

### Author(s):

[Various Authors](http://clustermapping.us/content/project-leadership-team)

### Abstract:

The U.S. Cluster Mapping Project is a national economic initiative that provides over 50 million open data records on industry clusters and regional business environments in the United States to promote economic growth and national competitiveness. The project is led by Harvard Business School's Institute for Strategy and Competitiveness in partnership with the U.S. Department of Commerce and U.S. Economic Development Administration.

Regional economies are the building blocks of U.S. competitiveness. The nation’s ability to produce high-value products and services depends on the creation and strengthening of regional clusters of industries that become hubs of innovation. Clusters, which are regional concentrations of related industries, are a striking feature of all modern economies, making regions uniquely competitive for jobs and private investment. On June 11, 2014, U.S. Secretary of Commerce Penny Pritzker announced the launch of the new, Beta version of the U.S. Cluster Mapping website, commenting that the tool "reinforces the federal government's commitment to promote America's clusters and provide businesses and organizations with the data and strategies they need to capitalize on their region's assets."

This resource provides a modern web experience, integrating comparable data and metrics on economic performance to highlight regional strengths and opportunities and empower regions and businesses to make informed decisions. With an extensive organization registry, the platform also aims to connect businesses with the organizations that are promoting their clusters, as well as enable users to share and discuss best practices in economic development, policy and innovation.

13\. Istanbul Urban Database
============================

![](images/submissions/14/istanbul-urban-database.jpg)

### Website(s):

[http://www.istanbulurbandatabase.com/](http://www.istanbulurbandatabase.com/)

### Author(s):

Nil Tuzcu

### Abstract:

Istanbul Urban Database (IUDB) is an interactive sustainable web mapping application for research and the public. IUDB blends a wide range of historical data, and is the most comprehensive online archive of Istanbul’s urban history. The project aims to preserve collective memory, and architectural and urban heritage of Istanbul in an open-access multimedia platform. By implementing 'interactive deep mapping' approach, the project presents a set of tools for users to develop historical narratives, uncover hidden cultural and social histories and eventually become part of this digital platform by contributing to it in many forms. Integrating architecture and urbanism into digital and spatial humanities, IUDB explores how emerging spatial and visual tools advance the field of history and urban research.

14\. The Rhythm of Food
=======================

![](images/submissions/14/rhythm-of-food.jpg)

### Website(s):

[http://rhythm-of-food.net/#food-trends](http://rhythm-of-food.net/#food-trends)

### Author(s):

Google News Lab and Truth & Beauty

### Abstract:

The Rhythm of Food is a collaboration between Google News Lab and Truth & Beauty. Together, we explore the hidden patterns in Google search trend data. This project sheds light on the many facets of food seasonality, as seen through the lens of search interest in the United States over the last twelve years. In the course of this project, we analyzed hundreds of ingredients, recipes, and other food related search terms. A good starting point was FooDB. Right now, the site comprises 201 topics and presents 135,025 individual data points. All Google search data comes from Google Trends. We used Google Knowledge Graph topics (which distinguishes e.g. "Apple computers" from the fruit) and focus on data from the United States.